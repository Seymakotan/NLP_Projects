{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-30T06:49:35.099200Z","iopub.execute_input":"2021-07-30T06:49:35.099530Z","iopub.status.idle":"2021-07-30T06:49:35.113484Z","shell.execute_reply.started":"2021-07-30T06:49:35.099499Z","shell.execute_reply":"2021-07-30T06:49:35.112364Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/turkish-sales-comments/hepsiburada.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM,  Dropout\nfrom tensorflow.python.keras.preprocessing.text import Tokenizer\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:35.114964Z","iopub.execute_input":"2021-07-30T06:49:35.115663Z","iopub.status.idle":"2021-07-30T06:49:35.121750Z","shell.execute_reply.started":"2021-07-30T06:49:35.115628Z","shell.execute_reply":"2021-07-30T06:49:35.120892Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/turkish-sales-comments/hepsiburada.csv')\ndf = data.copy()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:35.123606Z","iopub.execute_input":"2021-07-30T06:49:35.124193Z","iopub.status.idle":"2021-07-30T06:49:36.746956Z","shell.execute_reply.started":"2021-07-30T06:49:35.124159Z","shell.execute_reply":"2021-07-30T06:49:36.746154Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   Rating                                             Review\n0       1                            3 yıldır tık demedi. :)\n1       1                      3 yıldır kullanıyorum müthiş \n2       1  Ürün bugün elime geçti çok fazla inceleme fırs...\n3       1  Almaya karar verdim. Hemencecik geldi. Keyifle...\n4       1  Günlük kullanımınızı çok çok iyi karsılıyor kı...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rating</th>\n      <th>Review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3 yıldır tık demedi. :)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3 yıldır kullanıyorum müthiş</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Ürün bugün elime geçti çok fazla inceleme fırs...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Almaya karar verdim. Hemencecik geldi. Keyifle...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Günlük kullanımınızı çok çok iyi karsılıyor kı...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#0->negatif veri etiketi\n#1->pozitif veri etiketi\ndf['Rating'].unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:36.748483Z","iopub.execute_input":"2021-07-30T06:49:36.748841Z","iopub.status.idle":"2021-07-30T06:49:36.760722Z","shell.execute_reply.started":"2021-07-30T06:49:36.748805Z","shell.execute_reply":"2021-07-30T06:49:36.759673Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[1, 0]"},"metadata":{}}]},{"cell_type":"code","source":"# bütün verileri ve etiketleri listeye çeviriyoruz\ntarget = df['Rating'].values.tolist()#negatif=0, pozitif=1\ndata = df['Review'].values.tolist()#text verisi","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:36.762554Z","iopub.execute_input":"2021-07-30T06:49:36.763160Z","iopub.status.idle":"2021-07-30T06:49:36.782485Z","shell.execute_reply.started":"2021-07-30T06:49:36.763120Z","shell.execute_reply":"2021-07-30T06:49:36.781752Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#veriyi test ve train verisi olarak ayırıyoruz\n#datada veri var targetta etiket var. \nseperation = int(len(data) * 0.80)\nx_train, x_test = data[:seperation], data[seperation:]\ny_train, y_test = target[:seperation], target[seperation:]","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:36.783689Z","iopub.execute_input":"2021-07-30T06:49:36.784109Z","iopub.status.idle":"2021-07-30T06:49:36.797202Z","shell.execute_reply.started":"2021-07-30T06:49:36.784072Z","shell.execute_reply":"2021-07-30T06:49:36.796019Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\n#veri satır ve sütun sayısı\ndf.shape\n","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:36.800554Z","iopub.execute_input":"2021-07-30T06:49:36.801236Z","iopub.status.idle":"2021-07-30T06:49:36.809024Z","shell.execute_reply.started":"2021-07-30T06:49:36.801195Z","shell.execute_reply":"2021-07-30T06:49:36.807861Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(243497, 2)"},"metadata":{}}]},{"cell_type":"code","source":"# Verisetimizde en sık geçen 10000 kelimeyi alıyoruz\nnum_words = 10000\n\n# Keras ile tokenizer tanımlıyoruz\ntokenizer = Tokenizer(num_words=num_words)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:36.811429Z","iopub.execute_input":"2021-07-30T06:49:36.811927Z","iopub.status.idle":"2021-07-30T06:49:36.817844Z","shell.execute_reply.started":"2021-07-30T06:49:36.811885Z","shell.execute_reply":"2021-07-30T06:49:36.816863Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Tüm Veriyi tokenlara ayırıyoruz\ntokenizer.fit_on_texts(data)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:36.819317Z","iopub.execute_input":"2021-07-30T06:49:36.819880Z","iopub.status.idle":"2021-07-30T06:49:47.605150Z","shell.execute_reply.started":"2021-07-30T06:49:36.819832Z","shell.execute_reply":"2021-07-30T06:49:47.604267Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#tokenizer.word_index #kelimelerin tokenlaşmış halini görebilriizi.","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:47.606373Z","iopub.execute_input":"2021-07-30T06:49:47.606880Z","iopub.status.idle":"2021-07-30T06:49:47.611038Z","shell.execute_reply.started":"2021-07-30T06:49:47.606844Z","shell.execute_reply":"2021-07-30T06:49:47.610112Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Tokenizerı kaydediyoruz\nimport pickle\n\nwith open('turkish_tokenizer_hack.pickle', 'wb') as handle:\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:47.612385Z","iopub.execute_input":"2021-07-30T06:49:47.612709Z","iopub.status.idle":"2021-07-30T06:49:47.915231Z","shell.execute_reply.started":"2021-07-30T06:49:47.612672Z","shell.execute_reply":"2021-07-30T06:49:47.914368Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\n# Tokenizerı yüklüyoruz\nwith open('turkish_tokenizer_hack.pickle', 'rb') as handle:\n    turkish_tokenizer = pickle.load(handle)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:47.916559Z","iopub.execute_input":"2021-07-30T06:49:47.916938Z","iopub.status.idle":"2021-07-30T06:49:48.214310Z","shell.execute_reply.started":"2021-07-30T06:49:47.916901Z","shell.execute_reply":"2021-07-30T06:49:48.213336Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"biz modelimize kelimeleri train olarak vericez ama oradaki kelimeler string halinde tokenlaşmadılar bu yüzden onlarıda tokenlaştırıyoruz.","metadata":{}},{"cell_type":"code","source":"# Train verisi olarak ayırdığımız veriyi tokenizer ile tokenize ediyoruz\n\nx_train_tokens = turkish_tokenizer.texts_to_sequences(x_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:48.215883Z","iopub.execute_input":"2021-07-30T06:49:48.216269Z","iopub.status.idle":"2021-07-30T06:49:55.525148Z","shell.execute_reply.started":"2021-07-30T06:49:48.216231Z","shell.execute_reply":"2021-07-30T06:49:55.524168Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"x_train[100]\n","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:55.526486Z","iopub.execute_input":"2021-07-30T06:49:55.526886Z","iopub.status.idle":"2021-07-30T06:49:55.535151Z","shell.execute_reply.started":"2021-07-30T06:49:55.526848Z","shell.execute_reply":"2021-07-30T06:49:55.534188Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'Bu fiyata bu kalite kaçırmayın derim '"},"metadata":{}}]},{"cell_type":"code","source":"#yukarıdaki x_train[100] olan metni tokenlaştırdıkdan sonra aşağıdaki gibi rakamlarla temsil ediyoruz.\nx_train_tokens[100]\n#yanlış yazılmış kelimeler olabilir bunların token listemizde olması çok düşük 1 tane falan olur ama biz zaten modeli eğtiriken\n#ilk 10000 kelimeeyi tokenlaştırıyrouz. o yüzden etkisi olmuyor çok.","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:55.536980Z","iopub.execute_input":"2021-07-30T06:49:55.537825Z","iopub.status.idle":"2021-07-30T06:49:55.544902Z","shell.execute_reply.started":"2021-07-30T06:49:55.537773Z","shell.execute_reply":"2021-07-30T06:49:55.543968Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[5, 39, 5, 131, 323, 143]"},"metadata":{}}]},{"cell_type":"code","source":"# Test verisi olarak ayırdığımız veriyi tokenizer ile tokenize ediyoruz\n\nx_test_tokens = turkish_tokenizer.texts_to_sequences(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:55.546406Z","iopub.execute_input":"2021-07-30T06:49:55.546755Z","iopub.status.idle":"2021-07-30T06:49:57.475208Z","shell.execute_reply.started":"2021-07-30T06:49:55.546720Z","shell.execute_reply":"2021-07-30T06:49:57.474232Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#biz modelimize belirli inputlar veririz sabit boyutta bu yüzden bazı inputların size ı 5 ken bazıları 50 olabilir bunu standart haline\n#getirmek için az olanlara padding ekliyoruz ve 0 lar ile dolduryoruz.\n\n#Text verileri için padding yapıyoruz\n#RNN ağlarını kullanırken önceden belirdiğimiz sabit bir size olur. Tüm input textlerinin sizelarını bu sabit size için padding yaparak 0 lar\n#ile doldururuz.\n\nnum_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\nnum_tokens = np.array(num_tokens)\nprint(np.mean(num_tokens))\nnum_tokens.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:57.476766Z","iopub.execute_input":"2021-07-30T06:49:57.477176Z","iopub.status.idle":"2021-07-30T06:49:57.549994Z","shell.execute_reply.started":"2021-07-30T06:49:57.477136Z","shell.execute_reply":"2021-07-30T06:49:57.548703Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"20.744703220162876\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(243497,)"},"metadata":{}}]},{"cell_type":"code","source":"# Bütün text verileri içinde maximum token sayısına sahip olanı buluyoruz\nmax_tokens = np.mean(num_tokens) + 2*np.std(num_tokens) \nmax_tokens = int(max_tokens)\nmax_tokens","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:57.554521Z","iopub.execute_input":"2021-07-30T06:49:57.555040Z","iopub.status.idle":"2021-07-30T06:49:57.564415Z","shell.execute_reply.started":"2021-07-30T06:49:57.555001Z","shell.execute_reply":"2021-07-30T06:49:57.562973Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"59"},"metadata":{}}]},{"cell_type":"code","source":"# Bütün verilere padding yapıyoruz ve bütün veriler aynı boyutta oluyor\nx_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens)\nx_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:57.566470Z","iopub.execute_input":"2021-07-30T06:49:57.567077Z","iopub.status.idle":"2021-07-30T06:49:59.761997Z","shell.execute_reply.started":"2021-07-30T06:49:57.567037Z","shell.execute_reply":"2021-07-30T06:49:59.761046Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# size\nprint(x_train_pad.shape)\nprint(x_test_pad.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:59.763454Z","iopub.execute_input":"2021-07-30T06:49:59.763859Z","iopub.status.idle":"2021-07-30T06:49:59.769779Z","shell.execute_reply.started":"2021-07-30T06:49:59.763820Z","shell.execute_reply":"2021-07-30T06:49:59.768690Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"(194797, 59)\n(48700, 59)\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential() # Kullanacağımız Keras modelini tanımlıyoruz\n","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:49:59.771361Z","iopub.execute_input":"2021-07-30T06:49:59.772129Z","iopub.status.idle":"2021-07-30T06:50:01.688576Z","shell.execute_reply.started":"2021-07-30T06:49:59.772049Z","shell.execute_reply":"2021-07-30T06:50:01.687766Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"embedding_size = 50 # Her kelime için vektör boyutunu 50 olarak belirledik\n","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:50:01.689945Z","iopub.execute_input":"2021-07-30T06:50:01.690286Z","iopub.status.idle":"2021-07-30T06:50:01.695361Z","shell.execute_reply.started":"2021-07-30T06:50:01.690251Z","shell.execute_reply":"2021-07-30T06:50:01.694463Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#kelime vektörleri başlangıçta rastgele başlayacak ancak modeli eğitirken kelime vektörlerinide eğiticez. bu şeklide yaptığımızda kelime \n#vektörlerini word3wec kadar olmasada güzel bir sonunç alıcaz\n\n#Kerasta bir embedding layer oluşturuyoruz ve rastgele vektörler oluşturuyoruz\n\n# Modele embedding layer ekliyoruz\n# embedding matris size = num_words * embedding_size -> 10.000 * 50\n#10.000 e 50 bir matris oluşturuyoruz.\nmodel.add(Embedding(input_dim=num_words,\n                    output_dim=embedding_size,\n                    input_length=max_tokens,\n                    name='embedding_layer'))\n\n#bu layer input aldığı vektörleri bir sonraki layera gönderiyor. \n#örnek olarak \"bu ürün süper\" yorumun geldi 10k kelimenin arasından bu kelimelere karşılık gelen vektörleri alıcaz bir sonraki layera vericez","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:50:01.696956Z","iopub.execute_input":"2021-07-30T06:50:01.697589Z","iopub.status.idle":"2021-07-30T06:50:01.741438Z","shell.execute_reply.started":"2021-07-30T06:50:01.697552Z","shell.execute_reply":"2021-07-30T06:50:01.740730Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# 3-katmanlı(layer) LSTM\nmodel.add(LSTM(units=16, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=8, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=4, return_sequences=False)) # bir sonraki layer lstm olmadığı için false\nmodel.add(Dropout(0.2))\n# Dense layer: Tek nörondan oluşuyor ve değerler tek bir değer olarak sigmoide verilir\nmodel.add(Dense(1, activation='sigmoid'))# Sigmoid aktivasyon fonksiyonu","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:50:01.742500Z","iopub.execute_input":"2021-07-30T06:50:01.742818Z","iopub.status.idle":"2021-07-30T06:50:02.392261Z","shell.execute_reply.started":"2021-07-30T06:50:01.742768Z","shell.execute_reply":"2021-07-30T06:50:02.391433Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Adam optimizer\nfrom keras.optimizers import Adam\noptimizer = Adam(lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:50:02.393505Z","iopub.execute_input":"2021-07-30T06:50:02.393845Z","iopub.status.idle":"2021-07-30T06:50:02.400364Z","shell.execute_reply.started":"2021-07-30T06:50:02.393811Z","shell.execute_reply":"2021-07-30T06:50:02.399555Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Farklı optimizerları deniyoruz\nmodel.compile(loss='binary_crossentropy',\noptimizer='adam',\nmetrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:50:02.401641Z","iopub.execute_input":"2021-07-30T06:50:02.402142Z","iopub.status.idle":"2021-07-30T06:50:02.418302Z","shell.execute_reply.started":"2021-07-30T06:50:02.402086Z","shell.execute_reply":"2021-07-30T06:50:02.417488Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# modelin özeti\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:50:24.771573Z","iopub.execute_input":"2021-07-30T06:50:24.771924Z","iopub.status.idle":"2021-07-30T06:50:24.782611Z","shell.execute_reply.started":"2021-07-30T06:50:24.771895Z","shell.execute_reply":"2021-07-30T06:50:24.781660Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_layer (Embedding)  (None, 59, 50)            500000    \n_________________________________________________________________\nlstm (LSTM)                  (None, 59, 16)            4288      \n_________________________________________________________________\ndropout (Dropout)            (None, 59, 16)            0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 59, 8)             800       \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 59, 8)             0         \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 4)                 208       \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 4)                 0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 5         \n=================================================================\nTotal params: 505,301\nTrainable params: 505,301\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# epoch -> veri ile kaç kere eğiteceğiz\n# batch_size -> feeding size-her epochta kaç veri ile besleyeceğiz\nmodel.fit(np.array(x_train_pad), np.array(y_train), epochs=5, batch_size=256)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:52:22.746086Z","iopub.execute_input":"2021-07-30T06:52:22.746421Z","iopub.status.idle":"2021-07-30T06:53:33.838361Z","shell.execute_reply.started":"2021-07-30T06:52:22.746390Z","shell.execute_reply":"2021-07-30T06:53:33.837571Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/5\n761/761 [==============================] - 23s 17ms/step - loss: 0.3739 - accuracy: 0.9087\nEpoch 2/5\n761/761 [==============================] - 12s 16ms/step - loss: 0.1943 - accuracy: 0.9472\nEpoch 3/5\n761/761 [==============================] - 12s 15ms/step - loss: 0.1041 - accuracy: 0.9674\nEpoch 4/5\n761/761 [==============================] - 12s 16ms/step - loss: 0.0770 - accuracy: 0.9774\nEpoch 5/5\n761/761 [==============================] - 12s 16ms/step - loss: 0.0607 - accuracy: 0.9830\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fbf682ca190>"},"metadata":{}}]},{"cell_type":"code","source":"# model sonuçları\nresult = model.evaluate(np.array(x_test_pad), np.array(y_test))\nresult","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:55:02.262595Z","iopub.execute_input":"2021-07-30T06:55:02.262945Z","iopub.status.idle":"2021-07-30T06:55:10.454668Z","shell.execute_reply.started":"2021-07-30T06:55:02.262913Z","shell.execute_reply":"2021-07-30T06:55:10.453905Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"1522/1522 [==============================] - 8s 5ms/step - loss: 0.1441 - accuracy: 0.9525\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[0.144137442111969, 0.9525461792945862]"},"metadata":{}}]},{"cell_type":"code","source":"\n# doğruluk oranı\naccuracy = (result[1]) * 100\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:55:43.625853Z","iopub.execute_input":"2021-07-30T06:55:43.626194Z","iopub.status.idle":"2021-07-30T06:55:43.632922Z","shell.execute_reply.started":"2021-07-30T06:55:43.626165Z","shell.execute_reply":"2021-07-30T06:55:43.631845Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"95.25461792945862"},"metadata":{}}]},{"cell_type":"code","source":"#test yorumları(inputlar)\ntext1 = \"böyle bir şeyi kabul edemem\"\ntext2 = \"tasarımı güzel ancak ürün açılmış tavsiye etmem\"\ntext3 = \"bu işten çok sıkıldım artık\"\ntext4 = \"kötü yorumlar gözümü korkutmuştu ancak hiçbir sorun yaşamadım teşekkürler\"\ntext5 = \"yaptığın işleri hiç beğenmiyorum\"\ntext6 = \"tam bir fiyat performans ürünü beğendim\"\ntext7 = \"Bu ürünü beğenmedim\"\ntexts = [text1, text2,text3,text4,text5,text6,text7]","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:55:50.232529Z","iopub.execute_input":"2021-07-30T06:55:50.232941Z","iopub.status.idle":"2021-07-30T06:55:50.239011Z","shell.execute_reply.started":"2021-07-30T06:55:50.232910Z","shell.execute_reply":"2021-07-30T06:55:50.237913Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"tokens = turkish_tokenizer.texts_to_sequences(texts)\ntokens = turkish_tokenizer.texts_to_sequences(texts)\ntokens","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:56:03.529527Z","iopub.execute_input":"2021-07-30T06:56:03.529869Z","iopub.status.idle":"2021-07-30T06:56:03.538289Z","shell.execute_reply.started":"2021-07-30T06:56:03.529832Z","shell.execute_reply":"2021-07-30T06:56:03.537377Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"[[200, 2, 1231, 2558],\n [553, 7, 82, 4, 5984, 9, 1031],\n [5, 7293, 1, 214],\n [177, 735, 7728, 82, 263, 105, 326, 16],\n [3276, 46],\n [74, 2, 28, 111, 19, 146],\n [5, 19, 1365]]"},"metadata":{}}]},{"cell_type":"code","source":"#padding\ntokens_pad = pad_sequences(tokens, maxlen=max_tokens)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:56:11.790044Z","iopub.execute_input":"2021-07-30T06:56:11.790361Z","iopub.status.idle":"2021-07-30T06:56:11.795531Z","shell.execute_reply.started":"2021-07-30T06:56:11.790334Z","shell.execute_reply":"2021-07-30T06:56:11.793582Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#model bu yorumların hangi duyguya yakın olduğunu tahminliyor\nmodel.predict(tokens_pad)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:56:18.396381Z","iopub.execute_input":"2021-07-30T06:56:18.396721Z","iopub.status.idle":"2021-07-30T06:56:19.281245Z","shell.execute_reply.started":"2021-07-30T06:56:18.396692Z","shell.execute_reply":"2021-07-30T06:56:19.280437Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"array([[0.35313267],\n       [0.24135295],\n       [0.9894964 ],\n       [0.9956045 ],\n       [0.923757  ],\n       [0.9981462 ],\n       [0.10886286]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"for i in model.predict(tokens_pad):\n    if i < 0.5:\n        print(\"negatif\")#negatif yorum yapmış\n    else:\n        print(\"pozitif\")#pozitif yorum yapmış","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:56:29.665969Z","iopub.execute_input":"2021-07-30T06:56:29.666393Z","iopub.status.idle":"2021-07-30T06:56:29.719042Z","shell.execute_reply.started":"2021-07-30T06:56:29.666361Z","shell.execute_reply":"2021-07-30T06:56:29.718224Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"negatif\nnegatif\npozitif\npozitif\npozitif\npozitif\nnegatif\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom keras.models import load_model\n\nmodel.save('model_lstm.h5')  # modeli kaydediyoruz","metadata":{"execution":{"iopub.status.busy":"2021-07-30T06:56:51.986128Z","iopub.execute_input":"2021-07-30T06:56:51.986487Z","iopub.status.idle":"2021-07-30T06:56:52.040602Z","shell.execute_reply.started":"2021-07-30T06:56:51.986457Z","shell.execute_reply":"2021-07-30T06:56:52.039799Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}